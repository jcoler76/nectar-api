/**
 * MCP Tool Executor
 * Executes MCP tools generated by MCPServerGenerator
 * Handles database operations securely with proper validation
 */

const { logger } = require('../../utils/logger');
const DatabaseService = require('../database/DatabaseService');
const { decryptDatabasePassword } = require('../../utils/encryption');

class MCPToolExecutor {
  /**
   * Execute an MCP tool
   * @param {Object} tool - Tool definition
   * @param {Object} parameters - Tool parameters
   * @param {Object} context - Execution context (role, service, connection, user)
   * @returns {Promise<Object>} Tool execution result
   */
  async executeTool(tool, parameters, context) {
    try {
      logger.info('Executing MCP tool', {
        toolName: tool.name,
        handler: tool.handler,
        userId: context.user?.userId,
        organizationId: context.organizationId,
      });

      // Validate parameters against tool schema
      this.validateParameters(parameters, tool.inputSchema);

      // Route to appropriate handler
      const handler = this[tool.handler];
      if (!handler) {
        throw new Error(`Handler not found: ${tool.handler}`);
      }

      const result = await handler.call(this, tool, parameters, context);

      logger.info('MCP tool executed successfully', {
        toolName: tool.name,
        resultSize: JSON.stringify(result).length,
      });

      return {
        success: true,
        data: result,
        tool: tool.name,
        executedAt: new Date(),
      };
    } catch (error) {
      logger.error('MCP tool execution error', {
        toolName: tool.name,
        error: error.message,
        stack: error.stack,
      });

      return {
        success: false,
        error: error.message,
        tool: tool.name,
        executedAt: new Date(),
      };
    }
  }

  /**
   * Execute table query
   */
  async executeTableQuery(tool, parameters, context) {
    const { objectName, schema } = tool.metadata;
    const { filters, limit, offset, orderBy, columns } = parameters;

    const connectionConfig = await this.getConnectionConfig(context);

    // Build SELECT query
    const columnList = columns && columns.length > 0 ? columns.join(', ') : '*';
    let query = `SELECT ${columnList} FROM [${schema}].[${objectName}]`;

    // Add WHERE clause
    if (filters && Object.keys(filters).length > 0) {
      const whereClause = this.buildWhereClause(filters);
      query += ` WHERE ${whereClause}`;
    }

    // Add ORDER BY
    if (orderBy) {
      query += ` ORDER BY ${orderBy}`;
    } else {
      // Default ordering for pagination
      query += ` ORDER BY (SELECT NULL)`;
    }

    // Add pagination
    query += ` OFFSET ${offset || 0} ROWS FETCH NEXT ${limit || 100} ROWS ONLY`;

    logger.debug('Executing table query', { query, schema, objectName });

    const result = await DatabaseService.executeQuery(connectionConfig, query);

    return {
      rows: result.recordset || result,
      count: (result.recordset || result).length,
      query: query, // For debugging - remove in production
    };
  }

  /**
   * PERFORMANCE: Search table schema with summary mode
   * Returns lightweight summary by default to prevent "interrupted" errors
   * Based on lessons learned: large responses cause chat UI timeouts
   */
  async searchTableSchema(tool, parameters, context) {
    const { objectName, schema } = tool.metadata;
    const { keyword, includeFullSchema } = parameters;

    const connectionConfig = await this.getConnectionConfig(context);

    // Get column information
    const columnsQuery = `
      SELECT
        COLUMN_NAME as name,
        DATA_TYPE as dataType,
        CHARACTER_MAXIMUM_LENGTH as maxLength,
        IS_NULLABLE as nullable,
        COLUMN_DEFAULT as defaultValue,
        ORDINAL_POSITION as position
      FROM INFORMATION_SCHEMA.COLUMNS
      WHERE TABLE_SCHEMA = '${schema}'
        AND TABLE_NAME = '${objectName}'
      ORDER BY ORDINAL_POSITION
    `;

    const columns = await DatabaseService.executeQuery(connectionConfig, columnsQuery);
    const columnList = columns.recordset || columns;

    // Filter by keyword if provided
    let filteredColumns = columnList;
    if (keyword) {
      const searchTerm = keyword.toLowerCase();
      filteredColumns = columnList.filter(
        col =>
          col.name?.toLowerCase().includes(searchTerm) ||
          col.dataType?.toLowerCase().includes(searchTerm)
      );
    }

    // PERFORMANCE: Return summary by default (prevents "interrupted" errors)
    if (!includeFullSchema) {
      // Get primary keys
      const pkQuery = `
        SELECT COL_NAME(ic.object_id, ic.column_id) as columnName
        FROM sys.indexes i
        INNER JOIN sys.index_columns ic ON i.object_id = ic.object_id AND i.index_id = ic.index_id
        WHERE i.object_id = OBJECT_ID('${schema}.${objectName}')
          AND i.is_primary_key = 1
      `;

      const primaryKeys = await DatabaseService.executeQuery(connectionConfig, pkQuery);
      const pkList = (primaryKeys.recordset || primaryKeys).map(pk => pk.columnName);

      return {
        schema,
        tableName: objectName,
        summary: {
          totalColumns: columnList.length,
          matchingColumns: filteredColumns.length,
          primaryKeys: pkList,
          columnNames: filteredColumns.map(c => c.name),
          dataTypes: [...new Set(filteredColumns.map(c => c.dataType))],
        },
        hint: 'Use includeFullSchema: true to get complete column details',
      };
    }

    // Full schema requested
    return {
      schema,
      tableName: objectName,
      columnCount: filteredColumns.length,
      columns: filteredColumns,
      searchKeyword: keyword || null,
    };
  }

  /**
   * Analyze table schema
   */
  async analyzeTableSchema(tool, parameters, context) {
    const { objectName, schema } = tool.metadata;
    const { includeStatistics } = parameters;

    const connectionConfig = await this.getConnectionConfig(context);

    // Get column information
    const columnsQuery = `
      SELECT
        COLUMN_NAME as name,
        DATA_TYPE as dataType,
        CHARACTER_MAXIMUM_LENGTH as maxLength,
        IS_NULLABLE as nullable,
        COLUMN_DEFAULT as defaultValue
      FROM INFORMATION_SCHEMA.COLUMNS
      WHERE TABLE_SCHEMA = '${schema}'
        AND TABLE_NAME = '${objectName}'
      ORDER BY ORDINAL_POSITION
    `;

    const columns = await DatabaseService.executeQuery(connectionConfig, columnsQuery);

    // Get indexes
    const indexesQuery = `
      SELECT
        i.name as indexName,
        COL_NAME(ic.object_id, ic.column_id) as columnName,
        i.is_unique as isUnique,
        i.is_primary_key as isPrimaryKey
      FROM sys.indexes i
      INNER JOIN sys.index_columns ic ON i.object_id = ic.object_id AND i.index_id = ic.index_id
      WHERE i.object_id = OBJECT_ID('${schema}.${objectName}')
      ORDER BY i.name, ic.key_ordinal
    `;

    const indexes = await DatabaseService.executeQuery(connectionConfig, indexesQuery);

    const result = {
      schema,
      tableName: objectName,
      columns: columns.recordset || columns,
      indexes: indexes.recordset || indexes,
    };

    if (includeStatistics) {
      // Get row count and size
      const statsQuery = `
        SELECT
          SUM(p.rows) as rowCount,
          SUM(a.total_pages) * 8 / 1024.0 as sizeMB
        FROM sys.tables t
        INNER JOIN sys.partitions p ON t.object_id = p.object_id
        INNER JOIN sys.allocation_units a ON p.partition_id = a.container_id
        WHERE t.schema_id = SCHEMA_ID('${schema}')
          AND t.name = '${objectName}'
          AND p.index_id IN (0, 1)
      `;

      const stats = await DatabaseService.executeQuery(connectionConfig, statsQuery);
      result.statistics = stats.recordset?.[0] || stats[0];
    }

    return result;
  }

  /**
   * Execute table count
   */
  async executeTableCount(tool, parameters, context) {
    const { objectName, schema } = tool.metadata;
    const { filters } = parameters;

    const connectionConfig = await this.getConnectionConfig(context);

    let query = `SELECT COUNT(*) as count FROM [${schema}].[${objectName}]`;

    if (filters && Object.keys(filters).length > 0) {
      const whereClause = this.buildWhereClause(filters);
      query += ` WHERE ${whereClause}`;
    }

    const result = await DatabaseService.executeQuery(connectionConfig, query);

    return {
      count: result.recordset?.[0]?.count || result[0]?.count || 0,
      query,
    };
  }

  /**
   * Execute table insert
   */
  async executeTableInsert(tool, parameters, context) {
    const { objectName, schema } = tool.metadata;
    const { data, returnInserted } = parameters;

    if (!Array.isArray(data) || data.length === 0) {
      throw new Error('Data must be a non-empty array');
    }

    const connectionConfig = await this.getConnectionConfig(context);

    // Build INSERT query
    const columns = Object.keys(data[0]);
    const columnList = columns.map(c => `[${c}]`).join(', ');

    const insertedRecords = [];

    for (const record of data) {
      const values = columns
        .map(col => {
          const val = record[col];
          if (val === null || val === undefined) return 'NULL';
          if (typeof val === 'string') return `'${val.replace(/'/g, "''")}'`;
          if (typeof val === 'boolean') return val ? '1' : '0';
          return val;
        })
        .join(', ');

      let query = `INSERT INTO [${schema}].[${objectName}] (${columnList}) `;

      if (returnInserted) {
        query += `OUTPUT INSERTED.* `;
      }

      query += `VALUES (${values})`;

      const result = await DatabaseService.executeQuery(connectionConfig, query);

      if (returnInserted) {
        insertedRecords.push(result.recordset?.[0] || result[0]);
      }
    }

    return {
      insertedCount: data.length,
      records: returnInserted ? insertedRecords : undefined,
    };
  }

  /**
   * Execute table update
   */
  async executeTableUpdate(tool, parameters, context) {
    const { objectName, schema } = tool.metadata;
    const { data, filters, returnUpdated } = parameters;

    if (!filters || Object.keys(filters).length === 0) {
      throw new Error(
        'Filters are required for UPDATE operations to prevent accidental mass updates'
      );
    }

    const connectionConfig = await this.getConnectionConfig(context);

    // Build UPDATE query
    const setClause = Object.entries(data)
      .map(([key, val]) => {
        if (val === null || val === undefined) return `[${key}] = NULL`;
        if (typeof val === 'string') return `[${key}] = '${val.replace(/'/g, "''")}'`;
        if (typeof val === 'boolean') return `[${key}] = ${val ? '1' : '0'}`;
        return `[${key}] = ${val}`;
      })
      .join(', ');

    const whereClause = this.buildWhereClause(filters);

    let query = `UPDATE [${schema}].[${objectName}] SET ${setClause} `;

    if (returnUpdated) {
      query += `OUTPUT INSERTED.* `;
    }

    query += `WHERE ${whereClause}`;

    const result = await DatabaseService.executeQuery(connectionConfig, query);

    return {
      updatedCount: result.rowsAffected?.[0] || 0,
      records: returnUpdated ? result.recordset || [] : undefined,
    };
  }

  /**
   * Execute table delete
   */
  async executeTableDelete(tool, parameters, context) {
    const { objectName, schema } = tool.metadata;
    const { filters, confirm } = parameters;

    if (!confirm) {
      throw new Error('DELETE operations require explicit confirmation (confirm: true)');
    }

    if (!filters || Object.keys(filters).length === 0) {
      throw new Error(
        'Filters are required for DELETE operations to prevent accidental mass deletions'
      );
    }

    const connectionConfig = await this.getConnectionConfig(context);

    const whereClause = this.buildWhereClause(filters);
    const query = `DELETE FROM [${schema}].[${objectName}] WHERE ${whereClause}`;

    const result = await DatabaseService.executeQuery(connectionConfig, query);

    return {
      deletedCount: result.rowsAffected?.[0] || 0,
      query,
    };
  }

  /**
   * Execute view query
   */
  async executeViewQuery(tool, parameters, context) {
    // Views use the same query logic as tables
    return this.executeTableQuery(tool, parameters, context);
  }

  /**
   * Analyze view schema
   */
  async analyzeViewSchema(tool, parameters, context) {
    // Views use similar analysis to tables
    return this.analyzeTableSchema(tool, parameters, context);
  }

  /**
   * Execute stored procedure
   */
  async executeProcedure(tool, parameters, context) {
    const { objectName, schema } = tool.metadata;
    const { parameters: procParams } = parameters;

    const connectionConfig = await this.getConnectionConfig(context);

    // Build EXEC query
    const paramList = procParams
      ? Object.entries(procParams)
          .map(([key, val]) => {
            if (val === null || val === undefined) return `@${key} = NULL`;
            if (typeof val === 'string') return `@${key} = '${val.replace(/'/g, "''")}'`;
            if (typeof val === 'boolean') return `@${key} = ${val ? '1' : '0'}`;
            return `@${key} = ${val}`;
          })
          .join(', ')
      : '';

    const query = `EXEC [${schema}].[${objectName}] ${paramList}`;

    logger.debug('Executing procedure', { query, schema, objectName });

    const result = await DatabaseService.executeQuery(connectionConfig, query);

    return {
      recordsets: result.recordsets || [result.recordset || result],
      returnValue: result.returnValue,
      query,
    };
  }

  /**
   * Build WHERE clause from filters object
   */
  buildWhereClause(filters) {
    const conditions = [];

    for (const [key, value] of Object.entries(filters)) {
      if (typeof value === 'object' && !Array.isArray(value)) {
        // MongoDB-style operators: { "age": { "$gt": 18 } }
        for (const [op, val] of Object.entries(value)) {
          const sqlOp = this.convertOperator(op);
          const escapedVal = this.escapeValue(val);
          conditions.push(`[${key}] ${sqlOp} ${escapedVal}`);
        }
      } else {
        // Simple equality: { "status": "active" }
        const escapedVal = this.escapeValue(value);
        conditions.push(`[${key}] = ${escapedVal}`);
      }
    }

    return conditions.join(' AND ');
  }

  /**
   * Convert MongoDB-style operators to SQL
   */
  convertOperator(op) {
    const operatorMap = {
      $eq: '=',
      $ne: '!=',
      $gt: '>',
      $gte: '>=',
      $lt: '<',
      $lte: '<=',
      $in: 'IN',
      $nin: 'NOT IN',
      $like: 'LIKE',
    };

    return operatorMap[op] || '=';
  }

  /**
   * Escape value for SQL
   */
  escapeValue(value) {
    if (value === null || value === undefined) return 'NULL';
    if (typeof value === 'string') return `'${value.replace(/'/g, "''")}'`;
    if (typeof value === 'boolean') return value ? '1' : '0';
    if (Array.isArray(value)) {
      return `(${value.map(v => this.escapeValue(v)).join(', ')})`;
    }
    return value;
  }

  /**
   * Get database connection config from context
   */
  async getConnectionConfig(context) {
    const { service, connection } = context;

    const decryptedPassword = decryptDatabasePassword(connection.passwordEncrypted);

    return {
      host: connection.host,
      port: connection.port,
      user: connection.username,
      password: decryptedPassword,
      database: service.database,
      sslEnabled: connection.sslEnabled,
    };
  }

  /**
   * Validate parameters against JSON schema
   */
  validateParameters(parameters, schema) {
    // Basic validation - in production, use a JSON schema validator like ajv
    if (!schema || !schema.properties) return;

    const required = schema.required || [];

    for (const requiredField of required) {
      if (!(requiredField in parameters)) {
        throw new Error(`Missing required parameter: ${requiredField}`);
      }
    }

    // Type checking could be added here
  }

  /**
   * Query folder documents using RAG pipeline
   */
  async queryFolderDocuments(tool, parameters, context) {
    const { folderId } = tool.metadata;
    const { question, topK, minSimilarity } = parameters;
    const { organizationId, user } = context;

    const FolderQueryService = require('./FolderQueryService');

    const result = await FolderQueryService.queryFolder({
      folderId,
      organizationId,
      question,
      userId: user?.userId,
      apiKeyId: user?.apiKeyId,
      options: {
        topK: topK || 5,
        minSimilarity: minSimilarity || 0.5,
      },
    });

    return {
      answer: result.answer,
      sources: result.sources,
      relevantChunks: result.relevantChunks,
      metadata: {
        ...result.metadata,
        folderId,
        question,
      },
    };
  }

  /**
   * Search folder documents (vector search only, no LLM)
   */
  async searchFolderDocuments(tool, parameters, context) {
    const { folderId } = tool.metadata;
    const { query, topK, minSimilarity } = parameters;
    const { organizationId } = context;

    const EmbeddingService = require('./EmbeddingService');

    // Generate query embedding
    const queryEmbedding = await EmbeddingService.generateQueryEmbedding(query);

    // Search similar chunks
    const results = await EmbeddingService.searchSimilar({
      folderId,
      organizationId,
      queryEmbedding,
      topK: topK || 10,
      minSimilarity: minSimilarity || 0.6,
    });

    return {
      query,
      resultsCount: results.length,
      results: results.map(r => ({
        fileId: r.fileId,
        filename: r.filename,
        excerpt: r.chunkText.substring(0, 300) + (r.chunkText.length > 300 ? '...' : ''),
        similarity: r.similarity,
        chunkIndex: r.chunkIndex,
      })),
    };
  }

  /**
   * List files in folder
   */
  async listFolderFiles(tool, parameters, context) {
    const { folderId } = tool.metadata;
    const { includeStats } = parameters;
    const { organizationId } = context;

    const { PrismaClient } = require('@prisma/client');
    const prisma = new PrismaClient();

    try {
      const files = await prisma.fileStorage.findMany({
        where: {
          folderId,
          organizationId,
          isActive: true,
        },
        select: {
          id: true,
          filename: true,
          fileSize: true,
          mimeType: true,
          uploadedAt: true,
          uploadedBy: true,
        },
        orderBy: {
          uploadedAt: 'desc',
        },
      });

      let result = {
        folderId,
        fileCount: files.length,
        files: files.map(f => ({
          id: f.id,
          filename: f.filename,
          fileSize: parseInt(f.fileSize),
          mimeType: f.mimeType,
          uploadedAt: f.uploadedAt,
          uploadedBy: f.uploadedBy,
        })),
      };

      if (includeStats) {
        // Get embedding counts per file
        const embeddingStats = await prisma.fileEmbedding.groupBy({
          by: ['fileId'],
          where: { folderId },
          _count: true,
        });

        const embeddingMap = new Map();
        embeddingStats.forEach(stat => {
          embeddingMap.set(stat.fileId, stat._count);
        });

        result.files = result.files.map(file => ({
          ...file,
          embeddingCount: embeddingMap.get(file.id) || 0,
          isIndexed: embeddingMap.has(file.id),
        }));
      }

      await prisma.$disconnect();
      return result;
    } catch (error) {
      await prisma.$disconnect();
      throw error;
    }
  }

  /**
   * Get folder statistics
   */
  async getFolderStats(tool, parameters, context) {
    const { folderId } = tool.metadata;
    const { includeCosts, dateRange } = parameters;
    const { organizationId } = context;

    const { PrismaClient } = require('@prisma/client');
    const prisma = new PrismaClient();
    const EmbeddingService = require('./EmbeddingService');
    const FolderQueryService = require('./FolderQueryService');

    try {
      // Get folder info
      const folder = await prisma.fileFolder.findUnique({
        where: { id: folderId },
        select: {
          id: true,
          name: true,
          description: true,
          embeddingCount: true,
          lastIndexedAt: true,
          indexingStatus: true,
          mcpConfig: true,
          createdAt: true,
        },
      });

      if (!folder) {
        throw new Error('Folder not found');
      }

      // Get embedding stats
      const embeddingStats = await EmbeddingService.getFolderStats(folderId);

      // Get recent query count
      const recentQueryCount = await prisma.folderMCPQuery.count({
        where: {
          folderId,
          createdAt: {
            gte: new Date(Date.now() - 30 * 24 * 60 * 60 * 1000), // Last 30 days
          },
        },
      });

      let result = {
        folder: {
          id: folder.id,
          name: folder.name,
          description: folder.description,
          embeddingCount: folder.embeddingCount,
          lastIndexedAt: folder.lastIndexedAt,
          indexingStatus: folder.indexingStatus,
          createdAt: folder.createdAt,
        },
        embeddings: embeddingStats,
        queries: {
          last30Days: recentQueryCount,
        },
      };

      // Add cost data if requested
      if (includeCosts) {
        const startDate = dateRange?.start
          ? new Date(dateRange.start)
          : new Date(Date.now() - 30 * 24 * 60 * 60 * 1000);
        const endDate = dateRange?.end ? new Date(dateRange.end) : new Date();

        const usageStats = await FolderQueryService.getUsageStats(folderId, startDate, endDate);

        result.usage = {
          dateRange: { start: startDate, end: endDate },
          totalQueries: usageStats.totalQueries,
          totalTokens: usageStats.totalTokens,
          totalCost: usageStats.totalCost,
          avgRelevanceScore: usageStats.avgRelevanceScore,
          avgResponseTime: usageStats.avgResponseTime,
        };
      }

      await prisma.$disconnect();
      return result;
    } catch (error) {
      await prisma.$disconnect();
      throw error;
    }
  }
}

module.exports = new MCPToolExecutor();
